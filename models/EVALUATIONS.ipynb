{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Understand the key metrics to measure the performance of your recommender engine"],"metadata":{"id":"h2LBW-xLu2Jq"}},{"cell_type":"markdown","source":["# Resources"],"metadata":{"id":"eVZcoawkuT6A"}},{"cell_type":"markdown","source":["- [Blog post](https://medium.com/@AmyGrabNGoInfo/the-ultimate-guide-to-evaluating-your-recommendation-system-d4fc8d4423cc) for this notebook\n","- Video tutorial on[YouTube](https://www.youtube.com/watch?v=kZxgvtciJFk&list=PLVppujud2yJqshyM80nNDZgye-AFufyqF&index=3)\n","- More video tutorials on[recommendation system](https://www.youtube.com/playlist?list=PLVppujud2yJqshyM80nNDZgye-AFufyqF)\n","- More blog posts on[recommendation system](https://medium.com/@AmyGrabNGoInfo/list/recommendation-system-7ed442471466)\n","\n","For more information about data science and machine learning, please check out my[YouTube channel](https://www.youtube.com/channel/UCmbA7XB6Wb7bLwJw9ARPcYg), [Medium Page](https://medium.com/@AmyGrabNGoInfo) and [GrabNGoInfo.com](https://grabngoinfo.com/tutorials/), or follow GrabNGoInfo on [LinkedIn](https://www.linkedin.com/company/grabngoinfo/)."],"metadata":{"id":"tAdIvdYtuW2N"}},{"cell_type":"markdown","source":["隆Claro! Aqu铆 tienes un resumen esquem谩tico de la informaci贸n proporcionada:\n","\n","#  **Evaluaci贸n de Sistemas de Recomendaci贸n y Ranking** \n","\n","#### 1. **Introducci贸n**\n","   - **驴Qu茅 es un sistema de recomendaci贸n?**\n","     - Tarea de clasificaci贸n que devuelve una lista ordenada de elementos relevantes para un usuario.\n","   - **Principios de Evaluaci贸n**\n","     - Necesidad de predicciones del modelo y verdad fundamental para evaluar.\n","     - Importancia del par谩metro K para establecer el punto de corte de evaluaci贸n.\n","\n","#### 2. **Tipos de M茅tricas**\n","   - **M茅tricas Predictivas**\n","     - Eval煤an la precisi贸n de las predicciones del modelo.\n","   - **M茅tricas de Clasificaci贸n**\n","     - Miden la calidad de la clasificaci贸n de elementos relevantes.\n","   - **M茅tricas de Comportamiento**\n","     - Reflejan propiedades importantes del sistema, como diversidad y novedad.\n","\n","#### 3. **M茅tricas Predictivas**\n","   - **Precisi贸n en K**\n","     - Proporci贸n de elementos relevantes entre los K principales.\n","   - **Recordar en K**\n","     - Cobertura de elementos relevantes en los K principales.\n","   - **Puntuaci贸n F**\n","     - Equilibra precisi贸n y recuperaci贸n.\n","\n","#### 4. **M茅tricas de Clasificaci贸n**\n","   - **MRR (Rango Rec铆proco Medio)**\n","     - Mide qu茅 tan pronto se encuentra el primer elemento relevante.\n","   - **MAP (Precisi贸n Promedio en K)**\n","     - Eval煤a la precisi贸n promedio en diferentes niveles de recuperaci贸n.\n","   - **Tasa de Aciertos en K**\n","     - Proporci贸n de usuarios con al menos una recomendaci贸n relevante.\n","   - **NDCG (Ganancia Acumulativa Descontada Normalizada)**\n","     - Considera relevancia y posici贸n de elementos en la lista.\n","\n","#### 5. **M茅tricas de Comportamiento**\n","   - **Diversidad**\n","     - Eval煤a la variedad de elementos recomendados a los usuarios.\n","  \n","#### 6. **Conclusiones**\n","   - Las m茅tricas predictivas miden la precisi贸n de las predicciones.\n","   - Las m茅tricas de clasificaci贸n eval煤an la calidad de la clasificaci贸n.\n","   - Las m茅tricas de comportamiento reflejan propiedades importantes del sistema.\n","   - La combinaci贸n de m茅tricas ofrece una evaluaci贸n m谩s hol铆stica.\n","  \n","隆Espero que esto te ayude a entender mejor la evaluaci贸n de sistemas de recomendaci贸n y ranking! Si tienes alguna pregunta, no dudes en hacerla."],"metadata":{"id":"yPHgjdXa2n98"}},{"cell_type":"markdown","source":["# Introduction"],"metadata":{"id":"-Ds2TCvlvNB9"}},{"cell_type":"markdown","source":["Recommendation systems have become an integral part of our daily lives, shaping our experiences on e-commerce platforms, content streaming services, and social media networks. They help users navigate vast catalogs, find relevant items, and discover new products or content that they might enjoy. But how do we know if a recommendation system is doing a good job? This tutorial will guide you through the essential metrics for evaluating the performance of your recommendation system, ensuring it effectively meets user needs and enhances their experience.\n","\n","Please check out my previous tutorials on [user-based collaborative filtering](https://medium.com/grabngoinfo/recommendation-system-user-based-collaborative-filtering-a2e76e3e15c4) and [item-based collaborative filtering](https://medium.com/grabngoinfo/recommendation-system-item-based-collaborative-filtering-f5078504996a).\n","\n","Let's get started!"],"metadata":{"id":"OY9QYslavbTw"}},{"cell_type":"markdown","source":["# Group 1. Accuracy Metrics: Predicting User Preferences"],"metadata":{"id":"kJhheRjSvizb"}},{"cell_type":"markdown","source":["Accuracy metrics measure how well a recommendation system can predict user preferences. They are generally applicable to collaborative filtering methods, which leverage similarities between users or items to make recommendations."],"metadata":{"id":"6RrZXY6vvxzG"}},{"cell_type":"markdown","source":["**1.1 Mean Absolute Error (MAE)**: Calculates the average absolute difference between predicted and actual ratings.\n","\n","Here's a Python function to calculate the Mean Absolute Error (MAE) between predicted and actual ratings:"],"metadata":{"id":"iEr9EtEkv_Id"}},{"cell_type":"code","source":["def mean_absolute_error(actual_ratings, predicted_ratings):\n","    # Check if the lengths of actual_ratings and predicted_ratings are equal\n","    if len(actual_ratings) != len(predicted_ratings):\n","        raise ValueError(\"The length of actual_ratings and predicted_ratings must be the same.\")\n","\n","    n = len(actual_ratings)\n","    total_error = 0\n","\n","    # Iterate through the lists and calculate the absolute difference between actual and predicted ratings\n","    for i in range(n):\n","        total_error += abs(actual_ratings[i] - predicted_ratings[i])\n","\n","    # Calculate the average of absolute differences\n","    mae = total_error / n\n","    return mae\n","\n","# Example usage\n","actual_ratings = [3.5, 4.0, 2.0, 5.0, 3.0]\n","predicted_ratings = [3.0, 4.5, 1.5, 4.5, 2.5]\n","\n","# Call the mean_absolute_error function with actual_ratings and predicted_ratings\n","mae = mean_absolute_error(actual_ratings, predicted_ratings)\n","print(f\"Mean Absolute Error: {mae}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1o7-XZUpwI7D","outputId":"fc96b0a7-504d-4d07-a3b3-97a5ddab25d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Absolute Error: 0.5\n"]}]},{"cell_type":"markdown","source":["This function takes two lists as input, `actual_ratings` and `predicted_ratings`, and calculates the average absolute difference between them. If the lengths of the lists don't match, a ValueError is raised. The function returns the calculated MAE as a floating-point number.\n","\n","In the example usage, `actual_ratings` and `predicted_ratings` are two lists containing example ratings. The function is called with these lists, and the result is printed."],"metadata":{"id":"uM9R6PyLxALt"}},{"cell_type":"markdown","source":["**1.2 Root Mean Square Error (RMSE)**: Calculates the square root of the average squared differences between predicted and actual ratings. RMSE is more sensitive to large errors than MAE.\n","\n","Here's a Python function to calculate the Root Mean Square Error (RMSE) between predicted and actual ratings:"],"metadata":{"id":"VREJ0NqDwpmb"}},{"cell_type":"code","source":["import math\n","\n","def root_mean_square_error(actual_ratings, predicted_ratings):\n","    # Check if the lengths of actual_ratings and predicted_ratings are equal\n","    if len(actual_ratings) != len(predicted_ratings):\n","        raise ValueError(\"The length of actual_ratings and predicted_ratings must be the same.\")\n","\n","    n = len(actual_ratings)\n","    total_error = 0\n","\n","    # Iterate through the lists and calculate the squared difference between actual and predicted ratings\n","    for i in range(n):\n","        total_error += (actual_ratings[i] - predicted_ratings[i]) ** 2\n","\n","    # Calculate the square root of the average of squared differences\n","    rmse = math.sqrt(total_error / n)\n","    return rmse\n","\n","# Example usage\n","actual_ratings = [3.5, 4.0, 2.0, 5.0, 3.0]\n","predicted_ratings = [3.0, 4.5, 1.5, 4.5, 2.5]\n","\n","# Call the root_mean_square_error function with actual_ratings and predicted_ratings\n","rmse = root_mean_square_error(actual_ratings, predicted_ratings)\n","print(f\"Root Mean Square Error: {rmse}\")\n"],"metadata":{"id":"_gJEqz9txTzN","colab":{"base_uri":"https://localhost:8080/"},"outputId":"634e8f89-a210-4110-f866-49557e6cb149"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Root Mean Square Error: 0.5\n"]}]},{"cell_type":"markdown","source":["This function takes two lists as input, `actual_ratings` and `predicted_ratings`, and calculates the square root of the average squared differences between them. If the lengths of the lists don't match, a `ValueError` is raised. The function returns the calculated RMSE as a floating-point number.\n","\n","In the example usage, `actual_ratings` and `predicted_ratings` are two lists containing example ratings. The function is called with these lists, and the result is printed."],"metadata":{"id":"nH8sIjTVxX4I"}},{"cell_type":"markdown","source":["**1.3 Precision**: Measures the proportion of relevant recommendations out of all the recommended items.\n","\n","Here's a Python function to calculate Precision."],"metadata":{"id":"pIVQD-mhyGzC"}},{"cell_type":"code","source":["def precision(recommended_items, relevant_items):\n","    # Calculate the intersection of recommended_items and relevant_items\n","    true_positive = len(set(recommended_items).intersection(set(relevant_items)))\n","\n","    # Calculate the total number of recommended items\n","    total_recommended_items = len(recommended_items)\n","\n","    # Calculate precision\n","    precision_value = true_positive / total_recommended_items if total_recommended_items > 0 else 0\n","    return precision_value\n","\n","# Example usage\n","recommended_items = [1, 3, 5, 7, 9]\n","relevant_items = [2, 3, 5, 7, 11, 15, 20]\n","\n","precision_value = precision(recommended_items, relevant_items)\n","print(f\"Precision: {precision_value:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VV2HZMh3zm6k","outputId":"e6ba71b0-b4f4-4ce5-c0dd-f5510880e8a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision: 0.60\n"]}]},{"cell_type":"markdown","source":["This function takes two lists as input, `recommended_items` and `relevant_items`, and calculates the proportion of relevant recommendations by counting the number of items in the intersection of the two lists and dividing that by the total number of recommended items.\n","\n","In the example usage, `recommended_items` and `relevant_items` are two lists containing example item IDs."],"metadata":{"id":"Z-4yL9w_LOGf"}},{"cell_type":"markdown","source":["**1.4 Recall**: Measures the proportion of relevant recommendations out of all the relevant items.\n","\n","Here is a Python function for calculating recall:"],"metadata":{"id":"rV5_OQE60Zyx"}},{"cell_type":"code","source":["def recall(recommended_items, relevant_items):\n","    # Calculate the intersection of recommended_items and relevant_items\n","    true_positive = len(set(recommended_items).intersection(set(relevant_items)))\n","\n","    # Calculate the total number of relevant items\n","    total_relevant_items = len(relevant_items)\n","\n","    # Calculate recall\n","    recall_value = true_positive / total_relevant_items if total_relevant_items > 0 else 0\n","    return recall_value\n","\n","# Example usage\n","recommended_items = [1, 3, 5, 7, 9]\n","relevant_items = [2, 3, 5, 7, 11, 15, 20]\n","\n","recall_value = recall(recommended_items, relevant_items)\n","print(f\"Recall: {recall_value:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Hz2SLLH0ow3","outputId":"10192dfc-8105-487a-e5ae-65520694a45a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Recall: 0.43\n"]}]},{"cell_type":"markdown","source":["This function takes two lists as input, `recommended_items` and `relevant_items`, and calculates the proportion of relevant recommendations by counting the number of items in the intersection of the two lists and dividing that by the total number of relevant items.\n","\n","In the example usage, `recommended_items` and `relevant_items` are two lists containing example item IDs."],"metadata":{"id":"j8IUAiFO1bVS"}},{"cell_type":"markdown","source":["# **M茅tricas basadas en clasificaci贸n**\n","\n","Si tenemos un algoritmo de generaci贸n de candidatos que devuelve un orden clasificado de elementos y es menos probable que se utilicen o vean los elementos que se encuentran m谩s abajo en la lista, entonces se deben considerar las siguientes m茅tricas."],"metadata":{"id":"sn0bPbZqw1Mj"}},{"cell_type":"markdown","source":["## Group 2. Ranking Metrics: Quality Over Quantity"],"metadata":{"id":"-gqF3Qhp2h1M"}},{"cell_type":"markdown","source":["Ranking metrics assess the quality of the ranking of recommended items, ensuring that the most relevant items appear at the top of the list."],"metadata":{"id":"qUi9VGV72mqW"}},{"cell_type":"markdown","source":["**2.1 Mean Reciprocal Rank (MRR)**: Calculates the average of the reciprocal ranks of the first relevant recommendation for each user.\n","\n","The pros of Mean Reciprocal Rank (MRR) include:\n","\n","1. Position-aware: MRR takes into account the position of the first relevant item in the recommendation list, rewarding systems that rank relevant items higher. This makes it suitable for evaluating ranking-based recommendation systems where the order of items matters.\n","\n","2. Focus on the top-ranked item: MRR emphasizes the importance of the first relevant item in the list, making it a useful metric for scenarios where users are likely to focus on the top recommendations and ignore the rest.\n","\n","3. Average performance: MRR calculates the mean reciprocal rank across all users, providing an overall measure of the recommendation system's performance. This allows for a fair comparison of different algorithms or models, as it considers the average performance rather than specific user cases.\n","\n","4. Intuitive interpretation: MRR scores range from 0 to 1, with higher values indicating better performance. This makes it easy to interpret and compare the performance of different recommendation algorithms.\n","\n","The cons of Mean Reciprocal Rank (MRR) include:\n","\n","1. Limited scope: MRR focuses exclusively on the first relevant item in the list and does not take into account other relevant items or their positions. This can be a limitation in scenarios where multiple relevant items or the overall ranking quality are important.\n","\n","2. Binary relevance assumption: MRR assumes a binary relevance scale (either relevant or not relevant) and does not account for varying degrees of relevance on a continuous scale. This can be a limitation in situations where the relevance of items is not binary and needs to be quantified more granularly.\n","\n","3. Lack of personalization: While MRR provides an average performance measure across all users, it may not fully capture the personalized aspect of recommendation systems. A high MRR score does not necessarily guarantee that the recommendation system is providing good recommendations for each individual user.\n","\n","4. Sensitivity to outliers: MRR can be sensitive to outliers, as it calculates the reciprocal rank of the first relevant item for each user. A few users with very low reciprocal ranks can significantly impact the overall MRR score, potentially making it less reliable for evaluating the general performance of a recommendation system.\n","\n","Here is a Python function for calculating Mean Reciprocal Rank (MRR):"],"metadata":{"id":"DUamBE-x2w-N"}},{"cell_type":"code","source":["def mean_reciprocal_rank(recommended_items_list, relevant_items_list):\n","    if len(recommended_items_list) != len(relevant_items_list):\n","        raise ValueError(\"The length of recommended_items_list and relevant_items_list must be the same.\")\n","\n","    reciprocal_ranks = []\n","\n","    # Iterate through the lists of recommended items and relevant items for each user\n","    for recommended_items, relevant_items in zip(recommended_items_list, relevant_items_list):\n","        # Find the reciprocal rank for each user\n","        for rank, item in enumerate(recommended_items, start=1):\n","            if item in relevant_items:\n","                reciprocal_ranks.append(1 / rank)\n","                break\n","        else:\n","            reciprocal_ranks.append(0)\n","\n","    # Calculate the mean reciprocal rank\n","    mrr = sum(reciprocal_ranks) / len(reciprocal_ranks)\n","    return mrr\n","\n","# Example usage\n","recommended_items_list = [\n","    [1, 3, 5, 7, 9],\n","    [2, 4, 6, 8],\n","    [11, 12, 13, 14, 15, 16, 17]\n","]\n","\n","relevant_items_list = [\n","    [2, 3, 5, 7, 11],\n","    [1, 4, 6, 8, 9],\n","    [16, 17, 18, 19, 20]\n","]\n","\n","mrr = mean_reciprocal_rank(recommended_items_list, relevant_items_list)\n","print(f\"Mean Reciprocal Rank: {mrr:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CwUgrVq93-0x","outputId":"1455f197-cb21-4f2e-d0b2-af194e1f60c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Reciprocal Rank: 0.39\n"]}]},{"cell_type":"markdown","source":["This function takes two lists of lists as input, `recommended_items_list` and `relevant_items_list`, where each inner list represents the recommendations and relevant items for a specific user. It calculates the reciprocal rank for each user by finding the rank of the first relevant item in the recommended items list, then takes the average of these reciprocal ranks. The function returns the calculated MRR as a floating-point number.\n","\n","In the example usage, `recommended_items_list` and `relevant_items_list` are two lists of lists containing example item IDs for three users. The function is called with these lists, and the result is printed."],"metadata":{"id":"3K5U85UG54E-"}},{"cell_type":"markdown","source":["**2.2 Mean Average Precision (MAP)**: Calculates the average precision for each user and takes the mean across all users. It takes into account both the order and the relevance of recommended items.\n","\n","The pros of Mean Average Precision (MAP) include:\n","\n","1. Position-aware: MAP takes into account the position of relevant items in the recommendation list, rewarding systems that rank relevant items higher. This makes it suitable for evaluating ranking-based recommendation systems where the order of items matters.\n","\n","2. Relevance-aware: MAP considers the relevance of items by calculating the average precision for each user, which is the average of the precision scores at each relevant item's position. This means that it can distinguish between different levels of relevance when evaluating recommendations.\n","\n","3. Average performance: MAP calculates the mean average precision across all users, providing an overall measure of the recommendation system's performance. This allows for a fair comparison of different algorithms or models, as it considers the average performance rather than specific user cases.\n","\n","4. Robustness: MAP is less sensitive to outliers compared to some other metrics, as it calculates the average precision across multiple positions in the recommendation list for each user. This robustness makes it more reliable for evaluating the general performance of a recommendation system.\n","\n","The cons of Mean Average Precision (MAP) include:\n","1. Binary relevance assumption: MAP assumes a binary relevance scale (either relevant or not relevant) and does not account for varying degrees of relevance on a continuous scale. This can be a limitation in situations where the relevance of items is not binary and needs to be quantified more granularly.\n","\n","2. Lack of personalization: While MAP provides an average performance measure across all users, it may not fully capture the personalized aspect of recommendation systems. A high MAP score does not necessarily guarantee that the recommendation system is providing good recommendations for each individual user.\n","\n","3. Not suitable for all scenarios: MAP is more appropriate for recommendation scenarios where a ranked list of items is provided to users. It may not be suitable for other types of recommendation scenarios, such as collaborative filtering or content-based recommendations that do not involve explicit ranking.\n","\n","4. Complexity: The calculation of MAP can be more complex than other metrics like precision, recall, or F1-score, making it more difficult to interpret and explain to non-experts.\n","\n","Here is a Python code for calculating Mean Average Precision (MAP)."],"metadata":{"id":"yzZn1zqO5-rp"}},{"cell_type":"code","source":["def average_precision(recommended_items, relevant_items):\n","    true_positives = 0\n","    sum_precisions = 0\n","\n","    for rank, item in enumerate(recommended_items, start=1):\n","        if item in relevant_items:\n","            true_positives += 1\n","            precision_at_rank = true_positives / rank\n","            sum_precisions += precision_at_rank\n","\n","    return sum_precisions / len(relevant_items) if len(relevant_items) > 0 else 0\n","\n","\n","def mean_average_precision(recommended_items_list, relevant_items_list):\n","    if len(recommended_items_list) != len(relevant_items_list):\n","        raise ValueError(\"The length of recommended_items_list and relevant_items_list must be the same.\")\n","\n","    average_precisions = []\n","\n","    # Calculate the average precision for each user\n","    for recommended_items, relevant_items in zip(recommended_items_list, relevant_items_list):\n","        ap = average_precision(recommended_items, relevant_items)\n","        average_precisions.append(ap)\n","\n","    # Calculate the mean average precision across all users\n","    map_value = sum(average_precisions) / len(average_precisions)\n","    return round(map_value, 2)\n","\n","# Example usage\n","recommended_items_list = [\n","    [1, 3, 5, 7, 9],\n","    [2, 4, 6, 8],\n","    [11, 12, 13, 14, 15, 16, 17]\n","]\n","\n","relevant_items_list = [\n","    [2, 3, 5, 7, 11],\n","    [1, 4, 6, 8, 9],\n","    [16, 17, 18, 19, 20]\n","]\n","\n","map_value = mean_average_precision(recommended_items_list, relevant_items_list)\n","print(f\"Mean Average Precision: {map_value}\")"],"metadata":{"id":"I5Xg8Zjs6bTu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"809d5c02-f14d-41e1-c1ef-79d91a64dfbe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Average Precision: 0.29\n"]}]},{"cell_type":"markdown","source":["In this code, the `average_precision` function calculates the average precision for a given set of recommended items and relevant items. The `mean_average_precision` function calculates the mean average precision across all users by calling the `average_precision` function for each user and then averaging the results. The final MAP value is rounded to 2 decimal places."],"metadata":{"id":"7hVFwifv-NQG"}},{"cell_type":"markdown","source":["**2.3 Normalized Discounted Cumulative Gain (nDCG)**: Evaluates the ranking quality by assigning higher importance to relevant items appearing at the top of the recommendation list. It is normalized to ensure comparability across different users and queries.\n","\n","Normalized Discounted Cumulative Gain (nDCG) is a popular metric used to evaluate the quality of ranking in recommendation systems. It has several benefits:\n","\n","1. Position-aware: Unlike some other metrics, nDCG takes into account the position of the relevant items in the recommendation list. Items that are ranked higher (closer to the top) contribute more to the nDCG score, reflecting the fact that users are more likely to interact with items at the top of the list.\n","\n","2. Relevance-weighted: nDCG incorporates the relevance of each recommended item, allowing it to differentiate between items with varying degrees of relevance. This makes it suitable for situations where the relevance of items is not binary (e.g., partially relevant, highly relevant) and can be quantified on a continuous scale.\n","\n","3. Normalized: nDCG is normalized against the ideal ranking, which means it can be compared across different queries or users. This allows for a fair evaluation of the recommendation system's performance, even when the number of relevant items varies between users or queries.\n","\n","4. Suitable for diverse recommendation scenarios: nDCG is applicable to various recommendation scenarios, including search engine result ranking, collaborative filtering, and content-based recommendation. This makes it a versatile metric for evaluating different types of recommendation systems.\n","\n","5. Intuitive interpretation: nDCG scores range from 0 to 1, with higher values indicating better ranking quality. This makes it easy to interpret and compare the performance of different recommendation algorithms.\n","\n","The cons of Normalized Discounted Cumulative Gain (nDCG) include:\n","1. Complexity: The calculation of nDCG can be more complex than other metrics like precision, recall, or F1-score, making it more difficult to interpret and explain to non-experts.\n","\n","2. Lack of personalization: While nDCG provides a measure of ranking quality, it may not fully capture the personalized aspect of recommendation systems. A high nDCG score does not necessarily guarantee that the recommendation system is providing good recommendations for each individual user.\n","\n","3. Binary relevance assumption: Although nDCG can handle varying degrees of relevance, it is often used with binary relevance judgments in practice. This can be a limitation in situations where the relevance of items is not binary and needs to be quantified more granularly.\n","\n","4. Sensitive to the choice of the ideal ranking: The normalization factor in nDCG is based on the ideal ranking, which can sometimes be subjective or difficult to determine. The choice of the ideal ranking can influence the nDCG score, potentially affecting its consistency and reliability.\n","\n","Here's a Python function to calculate the Normalized Discounted Cumulative Gain (nDCG)."],"metadata":{"id":"tXUsv-I3-83a"}},{"cell_type":"code","source":["import math\n","def discounted_cumulative_gain(recommended_items, relevant_items):\n","    dcg = 0\n","    for i, item in enumerate(recommended_items, start=1):\n","        if item in relevant_items:\n","            dcg += 1 / (math.log2(i + 1))\n","    return dcg\n","\n","def ideal_discounted_cumulative_gain(recommended_items, relevant_items):\n","    sorted_relevant_items = sorted(relevant_items, key=lambda x: recommended_items.index(x) if x in recommended_items else float('inf'))\n","    return discounted_cumulative_gain(sorted_relevant_items, relevant_items)\n","\n","def normalized_discounted_cumulative_gain(recommended_items, relevant_items):\n","    dcg = discounted_cumulative_gain(recommended_items, relevant_items)\n","    idcg = ideal_discounted_cumulative_gain(recommended_items, relevant_items)\n","\n","    if idcg == 0:\n","        return 0\n","    else:\n","        return round(dcg / idcg, 2)\n","\n","# Example usage\n","recommended_items_list = [\n","    [1, 3, 5, 7, 9],\n","    [2, 4, 6, 8],\n","    [11, 12, 13, 14, 15, 16, 17]\n","]\n","\n","relevant_items_list = [\n","    [2, 3, 5, 7, 11],\n","    [1, 4, 6, 8, 9],\n","    [16, 17, 18, 19, 20]\n","]\n","\n","ndcg_values = [normalized_discounted_cumulative_gain(recommended, relevant)\n","               for recommended, relevant in zip(recommended_items_list, relevant_items_list)]\n","\n","print(f\"nDCG values: {ndcg_values}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"mIpiwJ-3_Lwa","outputId":"4f8188cd-96de-4dd7-8dbb-42e3caee6c1a","executionInfo":{"status":"error","timestamp":1708081571945,"user_tz":-60,"elapsed":272,"user":{"displayName":"Jaime","userId":"12571159925540429902"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["nDCG values: [0.53, 0.53, 0.23]\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'np' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-65fddafcee56>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"nDCG values: {ndcg_values}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0maverage_ndcg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndcg_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"nDCG promedio: {average_ndcg:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"]}]},{"cell_type":"markdown","source":["In this code, the `discounted_cumulative_gain` function calculates the DCG for a given set of recommended items and relevant items. The `ideal_discounted_cumulative_gain` function calculates the ideal DCG, which is the DCG value if the recommended items were perfectly ranked. The `normalized_discounted_cumulative_gain` function calculates the nDCG by dividing the DCG value by the ideal DCG value.\n","\n","The example usage calculates the nDCG values for three users with different recommended and relevant item lists. The nDCG values are printed for each user."],"metadata":{"id":"MyhmYWdSA3tF"}},{"cell_type":"markdown","source":["## Group 3. Coverage and Diversity Metrics: A Taste for Variety"],"metadata":{"id":"UO1d3k46A85d"}},{"cell_type":"markdown","source":["Coverage and diversity metrics measure the extent to which a recommendation system can provide a wide range of relevant and novel items, promoting exploration and discovery."],"metadata":{"id":"vhrtTJhLBBj_"}},{"cell_type":"markdown","source":["## **M茅tricas centradas en recomendaciones**"],"metadata":{"id":"a5Bet0lIyG0o"}},{"cell_type":"markdown","source":["**3.1 Catalog Coverage**: Measures the proportion of items in the catalog that are recommended at least once.\n","\n","Catalog coverage is an important metric in recommendation systems for several reasons:\n","\n","* Item exposure: Catalog coverage measures the proportion of items in the catalog that are recommended at least once. This provides insight into how well the recommendation system exposes different items in the catalog to users, ensuring that a wide variety of items have a chance to be recommended and discovered by users.\n","\n","* Long-tail items: A high catalog coverage indicates that the recommendation system is capable of suggesting not only popular items but also less popular or long-tail items. This can help promote niche items that cater to specific user interests, potentially increasing user satisfaction and overall revenue.\n","\n","* Diversification: Catalog coverage can serve as a proxy for the diversity of recommendations. A higher catalog coverage implies that the system is recommending a broader range of items, which can lead to a more diverse and engaging user experience.\n","\n","* Cold-start problem: Catalog coverage can help identify the cold-start problem, where the recommendation system struggles to recommend new or less popular items due to a lack of data. A low catalog coverage might indicate that the system is not well-suited for handling such situations, and alternative approaches or additional data sources should be considered.\n","\n","* Business goals: For businesses with a large and diverse catalog, it is essential to ensure that users are exposed to a wide variety of items. A high catalog coverage can contribute to achieving business goals such as increasing sales, user satisfaction, and user retention.\n","\n","* Evaluation and model comparison: Catalog coverage is a useful metric for comparing different recommendation models or evaluating improvements in the model over time. It can help assess the model's capability to recommend a broad range of items, which can be an important factor in selecting the best model for a particular application.\n","\n","Here's a Python function to calculate the Catalog Coverage."],"metadata":{"id":"q2ufj6ZPRpGS"}},{"cell_type":"code","source":["def catalog_coverage(recommended_items_list, catalog_items):\n","    # Flatten the list of recommended items and convert it to a set\n","    unique_recommended_items = set(item for sublist in recommended_items_list for item in sublist)\n","\n","    # Calculate the intersection of unique recommended items and catalog items\n","    covered_items = unique_recommended_items.intersection(catalog_items)\n","\n","    # Calculate the catalog coverage\n","    coverage = len(covered_items) / len(catalog_items)\n","    return coverage\n","\n","# Example usage\n","recommended_items_list = [\n","    [1, 3, 5, 7, 9],\n","    [2, 4, 6, 8],\n","    [11, 12, 13, 14, 15, 16, 17]\n","]\n","\n","catalog_items = set(range(1, 21))\n","\n","coverage = catalog_coverage(recommended_items_list, catalog_items)\n","print(f\"Catalog Coverage: {coverage}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PVVLtPXYSZle","outputId":"2ff8451d-dd0e-4bd4-d200-b64571f5e876"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Catalog Coverage: 0.8\n"]}]},{"cell_type":"markdown","source":["This function takes a list of lists `recommended_items_list`, where each inner list represents the recommended items for a specific user, and a set `catalog_items` representing all the items in the catalog. It calculates the catalog coverage by counting the number of unique recommended items and dividing that by the total number of items in the catalog. The function returns the calculated catalog coverage as a floating-point number.\n","\n","In the example usage, `recommended_items_list` contains example recommended items for three users, and `catalog_items` represents a catalog of 20 items."],"metadata":{"id":"TVUiQSBnSkLn"}},{"cell_type":"markdown","source":["**3.2 Prediction Coverage**: Measures the proportion of possible user-item pairs for which the recommendation system can make predictions.\n","\n","Prediction coverage provides valuable information about the recommendation model's ability to make predictions across the user-item space. It helps identify potential limitations, evaluate model performance, and ensure that the model is well-suited for the intended application.\n","\n","* Model limitations: Prediction coverage provides insight into the limitations of the recommendation model. A low prediction coverage indicates that the model is only able to make predictions for a small proportion of user-item pairs, which may lead to less diverse or less accurate recommendations.\n","\n","* Cold-start problem: Prediction coverage can help identify the cold-start problem, where the model struggles to make recommendations for new users or items due to a lack of data. A low prediction coverage might indicate that the model is not well-suited for handling such situations, and alternative approaches or additional data sources should be considered.\n","\n","* Diversity and personalization: A high prediction coverage indicates that the model can make predictions for a wide range of user-item pairs, which is desirable in a recommendation system to ensure that users receive diverse and personalized recommendations. This is particularly important when the user base and item catalog are large and varied.\n","\n","* Evaluation and model comparison: Prediction coverage is a useful metric to compare different recommendation models or to evaluate improvements in the model over time. It helps in understanding the model's capability to generate predictions across the entire user-item space, which can be a crucial factor in selecting the best model for a particular application.\n","\n","* Scalability: Prediction coverage can also be an indicator of the model's scalability. If a model can make predictions for a large number of user-item pairs, it may be better suited for handling larger datasets or growing catalogs.\n","\n","Here's a Python function to calculate the Prediction Coverage."],"metadata":{"id":"Rq7SrdsqSxPg"}},{"cell_type":"code","source":["def prediction_coverage(predicted_ratings, total_users, total_items):\n","    # Count the number of user-item pairs for which the recommendation system can make predictions\n","    predicted_pairs = sum(len(ratings) for ratings in predicted_ratings)\n","\n","    # Calculate the total number of possible user-item pairs\n","    total_possible_pairs = total_users * total_items\n","\n","    # Calculate the prediction coverage\n","    coverage = predicted_pairs / total_possible_pairs\n","    return coverage\n","\n","# Example usage\n","predicted_ratings = [\n","    {1: 3.5, 3: 4.0, 5: 2.5, 7: 3.0, 9: 4.5},\n","    {2: 4.5, 4: 3.0, 6: 2.0, 8: 3.5},\n","    {11: 3.5, 12: 4.0, 13: 2.5, 14: 3.0, 15: 4.5, 16: 3.5, 17: 2.0}\n","]\n","\n","total_users = 3\n","total_items = 20\n","\n","coverage = prediction_coverage(predicted_ratings, total_users, total_items)\n","print(f\"Prediction Coverage: {coverage:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T4eyRX0yTT8j","outputId":"1e30f3f9-a7a1-4961-eb59-a0cb84fa7bc8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction Coverage: 0.27\n"]}]},{"cell_type":"markdown","source":["This function takes a list of dictionaries `predicted_ratings`, where each dictionary represents the predicted item ratings for a specific user, and two integers `total_users` and `total_items` representing the total number of users and items, respectively. It calculates the prediction coverage by counting the number of user-item pairs for which the recommendation system can make predictions and dividing that by the total number of possible user-item pairs. The function returns the calculated prediction coverage as a floating-point number.\n","\n","In the example usage, `predicted_ratings` contains example predicted item ratings for three users, and there are 3 total users and 20 total items."],"metadata":{"id":"9yuzvRW6T-H5"}},{"cell_type":"markdown","source":["**3.3 Diversity**: Evaluates the dissimilarity between recommended items, ensuring that the recommendation list contains a good mix of different types of items.\n","\n","Diversity is important in recommendation systems because it helps ensure personalized and engaging experiences for users, supports exploration, reduces filter bubbles, promotes long-tail items, and enhances the robustness of the system.\n","\n","* Personalization: A diverse set of recommendations helps ensure that different users with varying interests and preferences receive personalized suggestions that cater to their unique tastes. This can lead to higher user satisfaction and better engagement.\n","\n","* Exploration: Diversity in recommendations allows users to explore and discover new items or content they may not have known about or considered previously. This can enhance the user experience by providing users with fresh and novel recommendations.\n","\n","* Reducing filter bubbles: Over-personalization can result in \"filter bubbles\" where users are only exposed to items that are similar to their previous choices. This can limit users' exposure to new ideas, perspectives, or experiences. Diverse recommendations help prevent filter bubbles by ensuring that users are exposed to a broader range of items.\n","\n","* Long-tail items: Diversity in recommendations can help promote long-tail items, which are items that may not be as popular but are still relevant to specific users. By recommending diverse items, the system can drive user engagement with a broader range of items, potentially increasing revenue and user satisfaction.\n","\n","* Robustness: A diverse set of recommendations is less susceptible to manipulation or bias. By ensuring that a wide variety of items are recommended, the system is more resistant to external factors like spam or targeted promotion of certain items.\n","\n","Here's a Python function to calculate the Diversity of the recommended items."],"metadata":{"id":"4lMEHNgOWT0k"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","def diversity(recommended_items_list, item_features):\n","    total_similarity = 0\n","    total_pairs = 0\n","\n","    for recommended_items in recommended_items_list:\n","        # Calculate pairwise cosine similarities for the recommended items\n","        similarities = cosine_similarity([item_features[item] for item in recommended_items])\n","        # Sum the similarities for all item pairs\n","        total_similarity += np.sum(similarities) - np.trace(similarities)  # Exclude the diagonal\n","        # Count the total number of item pairs\n","        total_pairs += len(recommended_items) * (len(recommended_items) - 1)\n","\n","    # Calculate the average similarity between item pairs\n","    avg_similarity = total_similarity / total_pairs if total_pairs > 0 else 0\n","    # Calculate the diversity by subtracting the average similarity from 1\n","    diversity = 1 - avg_similarity\n","    return diversity\n","\n","# Example usage\n","recommended_items_list = [\n","    [1, 3, 5, 7, 9],\n","    [2, 4, 6, 8],\n","    [11, 12, 13, 14, 15, 16, 17]\n","]\n","\n","# Example item features dictionary (using random feature vectors)\n","item_features = {item: np.random.rand(5) for item in range(1, 21)}\n","\n","diversity_value = diversity(recommended_items_list, item_features)\n","print(f\"Diversity: {diversity_value:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sCEEegHuWsyX","outputId":"899d58b1-a399-4d58-a01a-9e8c27b77b9b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Diversity: 0.23\n"]}]},{"cell_type":"markdown","source":["In this code, the diversity function calculates the diversity of the recommended items using cosine similarity. It takes a list of lists `recommended_items_list`, where each inner list represents the recommended items for a specific user, and a dictionary item_features representing the feature vectors for each item in the catalog.\n","\n","The function computes pairwise cosine similarities for the recommended items and calculates the diversity by subtracting the average similarity between item pairs from 1.\n","\n","In the example usage, `recommended_items_list` contains example recommended items for three users, and `item_features` represents a dictionary of random 5-dimensional feature vectors for 20 items. The function is called with these inputs, and the result is printed."],"metadata":{"id":"FP1KMyaRWzmH"}},{"cell_type":"markdown","source":["**3.4 Serendipity**: Measures the degree to which the recommended items are both relevant and unexpected, promoting the discovery of novel and interesting items.\n","\n","A recommendation list with serendipity can introduce users to items they may not have expected to enjoy or find relevant, leading to serendipitous discoveries. This can create a more enjoyable and engaging user experience.\n","\n","Measuring serendipity is a challenging task as it involves the combination of relevance, surprise, and novelty. Here's a Python function to calculate a basic version of Serendipity, which measures the degree to which the recommended items are both relevant and unexpected:"],"metadata":{"id":"md-7dFhoY8Fx"}},{"cell_type":"code","source":["def serendipity(recommended_items_list, relevant_items_list, popular_items, k=10):\n","    serendipity_score = 0\n","    total_users = len(recommended_items_list)\n","\n","    for recommended_items, relevant_items in zip(recommended_items_list, relevant_items_list):\n","        # Select the top-k recommended items\n","        top_k_recommended = recommended_items[:k]\n","\n","        # Find the serendipitous items by removing popular items from relevant items\n","        serendipitous_items = set(relevant_items) - set(popular_items)\n","\n","        # Count the number of serendipitous items in the top-k recommendations\n","        serendipitous_recommendations = len(set(top_k_recommended) & serendipitous_items)\n","\n","        # Calculate the proportion of serendipitous items in the top-k recommendations\n","        serendipity_score += serendipitous_recommendations / k\n","\n","    # Calculate the average serendipity score across all users\n","    avg_serendipity = serendipity_score / total_users\n","    return avg_serendipity\n","\n","# Example usage\n","recommended_items_list = [\n","    [1, 3, 5, 7, 9, 2, 4, 6, 8, 11],\n","    [2, 4, 6, 8, 1, 3, 5, 7, 9, 12],\n","    [11, 12, 13, 14, 15, 16, 17, 1, 3, 5]\n","]\n","\n","relevant_items_list = [\n","    [2, 3, 5, 7, 11, 13, 15, 17],\n","    [1, 4, 6, 8, 9, 11, 14, 16],\n","    [1, 3, 5, 7, 9, 11, 12, 13, 15, 17]\n","]\n","\n","popular_items = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n","\n","serendipity_value = serendipity(recommended_items_list, relevant_items_list, popular_items)\n","print(f\"Serendipity: {serendipity_value:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v6J1-J25bUWw","outputId":"5254d9c4-a10c-4c27-fd60-bd44cc68e11f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Serendipity: 0.20\n"]}]},{"cell_type":"markdown","source":["In this code, the serendipity function calculates the serendipity by first identifying serendipitous items (relevant but not popular items) and then calculating the proportion of serendipitous items in the top-k recommendations. It takes three lists of lists `recommended_items_list`, `relevant_items_list`, and a list of popular items popular_items. The function also accepts an optional parameter k, which is the number of top recommendations to consider (default is 10).\n","\n","In the example usage, recommended_items_list contains example recommended items for three users, `relevant_items_list` contains relevant items for the users, and `popular_items` is a list of popular items. The function is called with these inputs, and the result is printed. Note that this is a simple example, and other more sophisticated methods can be used to measure serendipity in recommendation systems."],"metadata":{"id":"KlM2Q9WOcvNz"}},{"cell_type":"markdown","source":["# M茅tricas de clasificaci贸n\n","\n","Las m茅tricas de clasificaci贸n eval煤an la capacidad de toma de decisiones de los sistemas de recomendaci贸n. Son una buena opci贸n para tareas como identificar productos relevantes o irrelevantes para el usuario. Para las m茅tricas de apoyo a la toma de decisiones, se ignora la calificaci贸n exacta, mientras que para los m茅todos basados en clasificaci贸n tiene una influencia impl铆cita a trav茅s de la clasificaci贸n.\n","\n","## M茅tricas de apoyo a la decisi贸n\n","\n","En funci贸n de todos los elementos recomendados en general para todos los usuarios, se pueden calcular la precisi贸n y la recuperaci贸n tradicionales. Los elementos recomendados que estaban disponibles en el conjunto de datos de prueba o que recibieron un alto valor de interacci贸n pueden considerarse predicciones precisas y viceversa. Esas m茅tricas requieren anotaciones por parte del usuario, traduciendo nuestro problema a un binario y estableciendo el n煤mero de recomendaciones principales consideradas (Top-N). Luego, con el uso de, digamos, el m贸dulo `sklearn.metrics`, podemos construir una matriz de confusi贸n y definir las m茅tricas de la siguiente manera:\n","\n","\n","\n","### **Precisi贸n@k**\n","Precision@k es una fracci贸n de los k elementos recomendados principales que son relevantes para el usuario\n","\n","P = (# de las k recomendaciones principales que son relevantes)/(# de art铆culos recomendados)\n"],"metadata":{"id":"EaTcLKujuwbJ"}},{"cell_type":"code","source":["def precisionK(recommended_items, relevant_items, k):\n","    \"\"\"\n","    Calcula la precisi贸n en k (Precision@k) dadas las recomendaciones y los elementos relevantes.\n","\n","    :param recommended_items: Una lista de los elementos recomendados.\n","    :param relevant_items: Una lista de los elementos relevantes para el usuario.\n","    :param k: El n煤mero de elementos principales a considerar.\n","    :return: La precisi贸n en k.\n","    \"\"\"\n","    if k <= 0:\n","        raise ValueError(\"k debe ser un entero positivo.\")\n","\n","    if len(recommended_items) == 0:\n","        return 0\n","\n","    # Tomamos solo los primeros k elementos recomendados\n","    recommended_at_k = recommended_items[:k]\n","\n","    # Contamos el n煤mero de elementos relevantes entre los k recomendados\n","    relevantes_entre_k = sum(1 for item in recommended_at_k if item in relevant_items)\n","\n","    # Calculamos la precisi贸n en k\n","    precision_at_k = relevantes_entre_k / k\n","\n","    return precision_at_k\n","\n","# Ejemplo de uso\n","recommended_items_ejemplo = ['a', 'b', 'c', 'd', 'e']\n","relevant_items_ejemplo = ['b', 'd', 'f']\n","k_ejemplo = 3\n","\n","precision_k_ejemplo = PrecisionK(recommended_items_ejemplo, relevant_items_ejemplo, k_ejemplo)\n","print(\"Precisi贸n@{}: {:.2f}\".format(k_ejemplo, precision_k_ejemplo))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tdyMUMNEvP-6","executionInfo":{"status":"ok","timestamp":1708000173908,"user_tz":-60,"elapsed":4,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"29abf4ca-e0e5-46ba-8d2f-9933dd74177f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Precisi贸n@3: 0.33\n"]}]},{"cell_type":"markdown","source":["## **Recall@k or HitRatio@k**\n","\n","Recall@k o HitRatio@k es una fracci贸n de los k elementos recomendados principales que se encuentran en un conjunto de elementos relevantes para el usuario. Tenga en cuenta que cuanto mayor sea k, mayor ser谩 el 铆ndice de aciertos, ya que existe una mayor probabilidad de que la respuesta correcta est茅 cubierta en las recomendaciones.\n","\n","R = (# de las k recomendaciones principales que son relevantes)/(# de todos los elementos relevantes)"],"metadata":{"id":"9_XRiZHtvvwr"}},{"cell_type":"code","source":["def recallK(recommended_items, relevant_items, k):\n","    \"\"\"\n","    Calcula el Recall en k (Recall@k) o Hit Ratio en k (HitRatio@k) dadas las recomendaciones y los elementos relevantes.\n","\n","    :param recommended_items: Una lista de los elementos recomendados.\n","    :param relevant_items: Una lista de los elementos relevantes para el usuario.\n","    :param k: El n煤mero de elementos principales a considerar.\n","    :return: El Recall en k.\n","    \"\"\"\n","    if k <= 0:\n","        raise ValueError(\"k debe ser un entero positivo.\")\n","\n","    if len(relevant_items) == 0:\n","        return 0\n","\n","    # Tomamos solo los primeros k elementos recomendados\n","    recommended_at_k = recommended_items[:k]\n","\n","    # Contamos el n煤mero de elementos relevantes entre los k recomendados\n","    relevantes_entre_k = sum(1 for item in recommended_at_k if item in relevant_items)\n","\n","    # Calculamos el Recall en k\n","    recall_at_k = relevantes_entre_k / len(relevant_items)\n","\n","    return recall_at_k\n","\n","# Ejemplo de uso\n","recommended_items_ejemplo = ['a', 'b', 'c', 'd', 'e']\n","relevant_items_ejemplo = ['b', 'd', 'f']\n","\n","k_ejemplo = 3\n","\n","recall_k_ejemplo = recallK(recommended_items_ejemplo, relevant_items_ejemplo, k_ejemplo)\n","print(\"Recall@{}: {:.2f}\".format(k_ejemplo, recall_k_ejemplo))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WDUleqbFvoH3","executionInfo":{"status":"ok","timestamp":1708000196418,"user_tz":-60,"elapsed":3,"user":{"displayName":"Jaime","userId":"12571159925540429902"}},"outputId":"3547c043-6299-42a8-be6a-d4e4b39f4ae1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Recall@3: 0.33\n"]}]},{"cell_type":"markdown","source":["## **F1@k**\n","\n","F1@k es una media arm贸nica de precisi贸n@k y recuperaci贸n@k que ayuda a simplificarlos en una sola m茅trica. Todas las m茅tricas anteriores se pueden calcular en funci贸n de la matriz de confusi贸n. Las f贸rmulas exactas se dan a continuaci贸n:"],"metadata":{"id":"SEir9esDwDui"}},{"cell_type":"code","source":["def f1K(recommended_items, relevant_items, k):\n","    \"\"\"\n","    Calcula el F1 en k (F1@k) dadas las recomendaciones y los elementos relevantes.\n","\n","    :param recommended_items: Una lista de los elementos recomendados.\n","    :param relevant_items: Una lista de los elementos relevantes para el usuario.\n","    :param k: El n煤mero de elementos principales a considerar.\n","    :return: El F1 en k.\n","    \"\"\"\n","    if k <= 0:\n","        raise ValueError(\"k debe ser un entero positivo.\")\n","\n","    if len(relevant_items) == 0:\n","        return 0\n","\n","    # Tomamos solo los primeros k elementos recomendados\n","    recommended_at_k = recommended_items[:k]\n","\n","    # Contamos el n煤mero de elementos relevantes entre los k recomendados\n","    relevantes_entre_k = sum(1 for item in recommended_at_k if item in relevant_items)\n","\n","    # Calculamos la precisi贸n en k\n","    precision = relevantes_entre_k / k\n","\n","    # Calculamos el recall en k\n","    recall = relevantes_entre_k / len(relevant_items)\n","\n","    # Calculamos el F1 en k\n","    if precision + recall == 0:\n","        f1_at_k = 0\n","    else:\n","        f1_at_k = 2 * (precision * recall) / (precision + recall)\n","\n","    return f1_at_k\n","\n","# Ejemplo de uso\n","recommended_items_ejemplo = ['a', 'b', 'c', 'd', 'e']\n","relevant_items_ejemplo = ['b', 'd', 'f']\n","k_ejemplo = 3\n","\n","f1_k_ejemplo = f1K(recommended_items_ejemplo, relevant_items_ejemplo, k_ejemplo)\n","print(\"F1@{}: {:.2f}\".format(k_ejemplo, f1_k_ejemplo))\n"],"metadata":{"id":"nnXtqREgwCAd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Summary"],"metadata":{"id":"4reFUoYnc3Bg"}},{"cell_type":"markdown","source":["\n","\n","Evaluating the performance of a recommendation system is crucial for its success, as it helps identify areas for improvement and ensures that it meets user needs. By understanding and applying these key metrics, you can optimize your recommender engine, enhance user satisfaction, and ultimately drive engagement and revenue for your platform. Remember, the most effective evaluation approach will depend on your specific use case and business goals, so always consider a combination of these metrics to get a comprehensive understanding of your system's performance. Happy recommending!\n","\n","\n","\n","\n"],"metadata":{"id":"AFge6sWcu8Ce"}},{"cell_type":"markdown","source":["# Recommended Tutorials"],"metadata":{"id":"Inx4sjhWY0Ua"}},{"cell_type":"markdown","source":["- [GrabNGoInfo Machine Learning Tutorials Inventory](https://medium.com/grabngoinfo/grabngoinfo-machine-learning-tutorials-inventory-9b9d78ebdd67)\n","- [Recommendation System: User-Based Collaborative Filtering](https://medium.com/p/recommendation-system-user-based-collaborative-filtering-a2e76e3e15c4)\n","- [Recommendation System: Item-Based Collaborative Filtering](https://medium.com/grabngoinfo/recommendation-system-item-based-collaborative-filtering-f5078504996a)\n","- [Topic Modeling with Deep Learning Using Python BERTopic](https://medium.com/p/topic-modeling-with-deep-learning-using-python-bertopic-cf91f5676504)\n","- [Five Ways To Create Tables In Databricks](https://medium.com/grabngoinfo/five-ways-to-create-tables-in-databricks-cd3847cfc3aa)\n","- [Hyperparameter Tuning for Time Series Causal Impact Analysis in Python](https://medium.com/grabngoinfo/hyperparameter-tuning-for-time-series-causal-impact-analysis-in-python-c8f7246c4d22)\n","- [Top 20 AB Test Interview Questions and Answers](https://medium.com/p/top-20-ab-test-interview-questions-and-answers-2d59cfc8c6df)\n","- [Top 10 Causal Inference Interview Questions and Answers](https://medium.com/p/top-10-causal-inference-interview-questions-and-answers-7c2c2a3e3f84)\n","- [Time Series Anomaly Detection Using Prophet in Python](https://medium.com/grabngoinfo/time-series-anomaly-detection-using-prophet-in-python-877d2b7b14b4)\n","- [Multivariate Time Series Forecasting with Seasonality and Holiday Effect Using Prophet in Python](https://medium.com/p/multivariate-time-series-forecasting-with-seasonality-and-holiday-effect-using-prophet-in-python-d5d4150eeb57)\n","- [Time Series Causal Impact Analysis in Python](https://medium.com/grabngoinfo/time-series-causal-impact-analysis-in-python-63eacb1df5cc)\n","- [3 Ways for Multiple Time Series Forecasting Using Prophet in Python](https://medium.com/p/3-ways-for-multiple-time-series-forecasting-using-prophet-in-python-7a0709a117f9)\n","- [Hierarchical Topic Model for Airbnb Reviews](https://medium.com/p/hierarchical-topic-model-for-airbnb-reviews-f772eaa30434)\n","- [Hyperparameter Tuning For XGBoost](https://medium.com/p/hyperparameter-tuning-for-xgboost-91449869c57e)\n","- [Four Oversampling And Under-Sampling Methods For Imbalanced Classification Using Python](https://medium.com/p/four-oversampling-and-under-sampling-methods-for-imbalanced-classification-using-python-7304aedf9037)\n","- [Explainable S-Learner Uplift Model Using Python Package CausalML](https://medium.com/grabngoinfo/explainable-s-learner-uplift-model-using-python-package-causalml-a3c2bed3497c)\n","- [One-Class SVM For Anomaly Detection](https://medium.com/p/one-class-svm-for-anomaly-detection-6c97fdd6d8af)\n","- [Hyperparameter Tuning and Regularization for Time Series Model Using Prophet in Python](https://medium.com/grabngoinfo/hyperparameter-tuning-and-regularization-for-time-series-model-using-prophet-in-python-9791370a07dc)\n","- [LASSO (L1) Vs Ridge (L2) Vs Elastic Net Regularization For Classification Model](https://medium.com/towards-artificial-intelligence/lasso-l1-vs-ridge-l2-vs-elastic-net-regularization-for-classification-model-409c3d86f6e9)\n","- [S Learner Uplift Model for Individual Treatment Effect and Customer Segmentation in Python](https://medium.com/grabngoinfo/s-learner-uplift-model-for-individual-treatment-effect-and-customer-segmentation-in-python-9d410746e122)\n","- [How to Use R with Google Colab Notebook](https://medium.com/p/how-to-use-r-with-google-colab-notebook-610c3a2f0eab)"],"metadata":{"id":"ZXz9AhVNZETE"}}]}