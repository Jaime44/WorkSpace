{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaime44/WorkSpace/blob/main/models/rnn_rs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juAAHlEpaJYN",
        "outputId": "6c31748b-c211-4b7f-c667-59be8f51fee7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "path_absolute = ''\n",
        "if IN_COLAB:\n",
        "    print(\"El código se está ejecutando en Google Colab.\")\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount('/content/drive')\n",
        "    path_absolute = '/content/drive/Othercomputers/Mi_portátil/TFM/WorkSpace/Models/neural network'\n",
        "\n",
        "    # Cambia al directorio de tu carpeta en Google Drive\n",
        "    os.chdir(path_absolute)\n",
        "\n",
        "    # Lista los archivos y carpetas en el directorio actual\n",
        "    contenido_carpeta = os.listdir(path_absolute)\n",
        "    print(\"Contenido de la carpeta en Google Drive:\")\n",
        "    print(contenido_carpeta)\n",
        "else:\n",
        "    print(\"El código se está ejecutando en un entorno local.\")\n",
        "    path_absolute = os.getcwd().replace(\"\\\\\", \"/\")\n",
        "    path_absolute = 'C:/Users/jaime/OneDrive - Universidad de Málaga/Escritorio/UNIR/TFM/WorkSpace/Models/neural network'\n",
        "\n",
        "datasets_path = \"/datasets/\"\n",
        "path_absolute = path_absolute+datasets_path\n",
        "\n",
        "path_workspace ='C:/Users/jaime/OneDrive - Universidad de Málaga/Escritorio/UNIR/TFM/WorkSpace/'\n",
        "sys.path.append(path_workspace)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jaef6KzRaJYQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import matplotlib as mpl\n",
        "import Utils.utils as util\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from IPython.display import SVG\n",
        "from wordcloud import WordCloud\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
        "from keras.layers import Dense,Dropout,Flatten,Embedding,BatchNormalization,Concatenate,Add,Concatenate,Dot,Input,dot,concatenate\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Configure visualisations\n",
        "%matplotlib inline\n",
        "mpl.style.use( 'ggplot' )\n",
        "plt.style.use('fivethirtyeight')\n",
        "sns.set(context=\"notebook\", palette=\"dark\", style = 'whitegrid' , color_codes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYOYZ4YfaJYS"
      },
      "outputs": [],
      "source": [
        "# dataFrame = pd.read_csv(path_absolute+'df_movies_rating_2.csv', sep=',')\n",
        "# data = dataFrame.copy()\n",
        "\n",
        "# tamano_muestra = 60000\n",
        "# # Obtiene una muestra aleatoria uniforme del DataFrame\n",
        "# data = data.sample(n=tamano_muestra, random_state=42)  # random_state para reproducibilidad\n",
        "\n",
        "\n",
        "# # Quito las calumnas categoricas de título y tag ambas estan represnetadas en las columnas númericas de tag_encode e id movie.\n",
        "# # util.contar_ocurrencias(data, '(no genres listed)')\n",
        "# # util.mostrar_filas_por_valor(data, '(no genres listed)', 1)\n",
        "\n",
        "# # Total de clases(Puntuaciones) a predecir\n",
        "# # 4.0,5.0,3.5,4.5,3.0,2.5,1.0,1.5,0.5\n",
        "# data = util.eliminar_columnas(data, ['tag', 'title', '(no genres listed)'])\n",
        "# util.contar_ocurrencias(data, 'rating')\n",
        "\n",
        "# data = util.eliminar_columnas(data, ['timestamp_tags', 'timestamp_scr'])\n",
        "\n",
        "# data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Carga de datos y preprocesado\n",
        "\n",
        "dataFrame = pd.read_csv(path_absolute+'/df_mezclado_tags_ratings_movies_links_genTags.csv')\n",
        "\n",
        "print(dataFrame.shape)\n",
        "\n",
        "data = dataFrame.copy()\n",
        "data = data.sample(n=8000, random_state=42)\n",
        "\n",
        "# Inserta la columna 'rating' en la última posición del DataFrame\n",
        "data.insert(len(data.columns)-1, 'rating', data.pop('rating'))\n",
        "# Inserta la columna 'relevance' en la penúltima posición del DataFrame\n",
        "data.insert(len(data.columns)-2, 'relevance', data.pop('relevance'))\n",
        "# Inserta la columna 'tag_etiquetas_genómicas' despues de tag_df_mezclado\n",
        "data.insert(5, 'tag_etiquetas_genómicas', data.pop('tag_etiquetas_genómicas'))\n",
        "\n",
        "# Renombrar algunas columnas:\n",
        "data.rename(columns={'timestamp_valoraciones': 'timestamp_rt', 'timestamp_etiquetas': 'timestamp_tags', \n",
        "                     'tag_df_mezclado_tags_ratings_movies_links_genMov': 'tag_by_user', \n",
        "                     'tag_etiquetas_genómicas': 'gen_tag'}, inplace=True)\n",
        "\n",
        "# Elimino las columnas:\n",
        "columnas_a_eliminar = ['imdbId', 'tmdbId']\n",
        "data = data.drop(columnas_a_eliminar, axis=1)\n",
        "print(data.shape)\n",
        "df = data.copy()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explore dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsfUuaGvaJYV",
        "outputId": "ca3e4874-08ce-4cda-da3f-e56080fc498c"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Valores nulos \n",
        "print(f\"Valores nulos para la columna userId: {df['userId'].isnull().sum()}\")\n",
        "print(f\"Valores nulos para la columna rating: {df['rating'].isnull().sum()}\")\n",
        "print(f\"Valores nulos para la columna movieId: {df['movieId'].isnull().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se cuenta los valores unicos de rating\n",
        "df['rating'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se cuenta los valores unicos de usuarios\n",
        "df['userId'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Se cuenta los valores unicos de peliculas\n",
        "df['movieId'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rango_valores = df['rating'].describe()['min'], df['rating'].describe()['max']\n",
        "print(\"Rango de valores cd rating:\", rango_valores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#promedio de calificaciones agrupado por titulos\n",
        "df.groupby('title')['rating'].mean().sort_values(ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cuantos generos distintos hay y cuantqas peliculas clasificadas con ese genero entre otros. \n",
        "genres = {}\n",
        "def find_genres():\n",
        "    for genre in df['genres']:\n",
        "        words = genre.split('|')\n",
        "        for word in words:\n",
        "            genres[word] = genres.get(word, 0) + 1\n",
        "find_genres()\n",
        "genres['None'] = genres.pop('(no genres listed)')\n",
        "genres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Nube de palabras para los generos\n",
        "wordcloud = WordCloud(width=800, height=500, background_color = 'white',\n",
        "                      min_font_size=6, contour_color='black', contour_width=2).generate_from_frequencies(genres)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Peliculas más puntuadas\n",
        "df_n_ratings = pd.DataFrame(df.groupby('title')['rating'].mean())\n",
        "df_n_ratings['total ratings'] = pd.DataFrame(df.groupby('title')['rating'].count())\n",
        "df_n_ratings.rename(columns = {'rating': 'mean ratings'}, inplace=True)\n",
        "df_n_ratings.sort_values('total ratings', ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# histograma de la distribución de frecuencia del número total de calificaciones en el DataFrame\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(df_n_ratings['total ratings'], bins=50, kde=True)  # kde=True incluye la estimación de densidad kernel\n",
        "plt.xlabel('Número total de calificaciones')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calificaciones promedio más altas en función de la columna 'mean ratings'.\n",
        "df_n_ratings.sort_values('mean ratings', ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Nº total de usuarios que han valorado con 5,0 : ', len(df_n_ratings.loc[df_n_ratings['mean ratings'] == 5]), '\\n')\n",
        "print('Nº total de usuarios individuales que han valorado con 5,0 : ', len(df_n_ratings.loc[(df_n_ratings['mean ratings'] == 5) \n",
        "                                                                           & (df_n_ratings['total ratings'] == 1)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(df_n_ratings['mean ratings'], bins=50, kde=True)\n",
        "plt.xlabel('Media de calificaciones')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mean Ratings vs Total Number of Ratings\n",
        "sns.jointplot(x='mean ratings', y='total ratings', data=df_n_ratings, height=8, ratio=4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MODELS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# La asignación de índices únicos y la posterior división del DataFrame en conjuntos de entrenamiento y \n",
        "# prueba pueden ser necesarias por varias razones en el contexto de modelos de recomendación y \n",
        "# aprendizaje automático en general:\n",
        "\n",
        "# Índices numéricos: Algunos algoritmos y modelos de aprendizaje automático requieren que las \n",
        "# entradas sean números enteros. Al asignar índices únicos a los usuarios y películas, \n",
        "# se asegura de que cada entidad esté representada por un identificador numérico único, \n",
        "# lo que facilita el procesamiento por parte de los modelos.\n",
        "\n",
        "# Consistencia en los datos de entrada: Al asignar índices únicos y transformar los datos originales, \n",
        "# se crea una representación consistente y única para cada usuario y película en el conjunto de datos. \n",
        "# Esto facilita el manejo y la interpretación de los datos durante el preprocesamiento y el entrenamiento \n",
        "# del modelo.\n",
        "\n",
        "# Reproducibilidad: La división aleatoria del DataFrame en conjuntos de entrenamiento y \n",
        "# prueba utilizando np.random.rand() con una semilla (random_state) proporciona reproducibilidad. \n",
        "# Esto significa que si vuelves a ejecutar el código con la misma semilla, obtendrás la misma \n",
        "# división de datos, lo que es útil para comparar resultados y depurar el código.\n",
        "\n",
        "# Evaluación del modelo: La división en conjuntos de entrenamiento y prueba es esencial para \n",
        "# evaluar el rendimiento del modelo. El conjunto de entrenamiento se utiliza para entrenar el modelo,\n",
        "# mientras que el conjunto de prueba se reserva para evaluar su rendimiento en datos no vistos.\n",
        "\n",
        "# En resumen, estas operaciones son prácticas comunes en el preprocesamiento de datos para modelos \n",
        "# de aprendizaje automático, especialmente cuando se trata de conjuntos de datos que contienen \n",
        "# variables categóricas o identificadores que deben ser representados de manera numérica y \n",
        "# cuando se busca garantizar la consistencia y la reproducibilidad en el procesamiento de datos.\n",
        "\n",
        "df_aux = df.copy()\n",
        "# userId\tmovieId\ttimestamp_rt\ttag_by_user\ttimestamp_tags\tgen_tag\ttitle\tgenres\ttagId\trelevance\trating\n",
        "df_aux = df_aux[['userId', 'movieId','tag_by_user','genres','rating']]\n",
        "\n",
        "# Crear diccionarios de asignación de índices únicos\n",
        "user_unique_ids = df_aux['userId'].unique()\n",
        "movie_unique_ids = df_aux['movieId'].unique()\n",
        "\n",
        "userid2idx = {user_id: idx for idx, user_id in enumerate(user_unique_ids)}\n",
        "movieid2idx = {movie_id: idx for idx, movie_id in enumerate(movie_unique_ids)}\n",
        "\n",
        "# Aplicar la asignación de índices únicos al DataFrame\n",
        "df_aux['userId'] = df_aux['userId'].apply(lambda x: userid2idx[x])\n",
        "df_aux['movieId'] = df_aux['movieId'].apply(lambda x: movieid2idx[x])\n",
        "\n",
        "# Dividir dataset en entrenamiento y test\n",
        "X = df_aux[['userId', 'movieId']]  # UserId y movieId\n",
        "Y = df_aux['rating']                # rating\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(x_train.shape , x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Definicicón de parametros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definición del número de factores latentes\n",
        "n_latent_factors = 50\n",
        "# learning_rate = 5e-4\n",
        "lr = 5e-4\n",
        "#Optimizador \n",
        "optimizer = Adam(learning_rate = lr)\n",
        "#Función de perdida\n",
        "loss_function = 'mse'\n",
        "#Bartch\n",
        "batch_size = 128\n",
        "#Epoch\n",
        "epochs = 20\n",
        "#Paciencia early stopping\n",
        "pte = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "es = EarlyStopping(monitor=\"val_loss\",\n",
        "                   mode=\"min\",\n",
        "                   verbose=1,\n",
        "                   patience=pte)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model):\n",
        "    # Entrenar el modelo y obtener el objeto history\n",
        "    history = model.fit(x=[x_train['userId'], x_train['movieId']], y=y_train, \n",
        "                       batch_size= batch_size, epochs=epochs, verbose= 1, \n",
        "                       validation_data=([x_test['userId'], x_test['movieId']], y_test))\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_loss(history):\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    accuracy = history.history['accuracy']\n",
        "    val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "    fig, ax1 = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "    color = 'tab:red'\n",
        "    ax1.set_xlabel('Epochs')\n",
        "    ax1.set_ylabel('Loss', color=color)\n",
        "    ax1.plot(loss, 'r--', label='Training Loss')\n",
        "    ax1.plot(val_loss, 'b-', label='Validation Loss')\n",
        "    ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "    ax2 = ax1.twinx()  \n",
        "    color = 'tab:green'\n",
        "    ax2.set_ylabel('Accuracy', color=color)\n",
        "    ax2.plot(accuracy, 'g-.', label='Training Accuracy')\n",
        "    ax2.plot(val_accuracy, 'y:', label='Validation Accuracy')\n",
        "    ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "    # Añadir leyendas\n",
        "    ax1.legend(loc='upper left')\n",
        "    ax2.legend(loc='upper right')\n",
        "\n",
        "    fig.tight_layout()  \n",
        "    plt.title('Model Loss and Accuracy')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Arquitectura 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "K.clear_session()\n",
        "tf.random.set_seed(51)\n",
        "np.random.seed(51)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtención del número único de usuarios y películas en el conjunto de datos de calificaciones\n",
        "n_users, n_movies = len(df['userId'].unique()), len(df['movieId'].unique())\n",
        "\n",
        "# Definición de la entrada del usuario\n",
        "user_input = Input(shape=(1,), name='User_Input')\n",
        "\n",
        "# Creación de la capa de embedding para usuarios\n",
        "user_embeddings = Embedding(input_dim=n_users, output_dim=n_latent_factors, input_length=1, \n",
        "                            name='User_Embedding')(user_input)\n",
        "user_vector = Flatten(name='User_Vector')(user_embeddings)\n",
        "\n",
        "# Definición de la entrada de la película\n",
        "movie_input = Input(shape=(1,), name='Movie_Input')\n",
        "\n",
        "# Creación de la capa de embedding para películas\n",
        "movie_embeddings = Embedding(input_dim=n_movies, output_dim=n_latent_factors, input_length=1, \n",
        "                             name='Movie_Embedding')(movie_input)\n",
        "movie_vector = Flatten(name='Movie_Vector')(movie_embeddings)\n",
        "\n",
        "# Combinación de los vectores de usuario y película mediante el producto punto\n",
        "merged_vectors = dot([user_vector, movie_vector], name='Dot_Product', axes=1)\n",
        "\n",
        "# Creación del modelo utilizando Model API de Keras\n",
        "model_a1 = Model([user_input, movie_input], merged_vectors)\n",
        "\n",
        "model_a1.summary()\n",
        "# Visualizar el modelo de Keras en formato DOT y luego lo convierte a formato SVG para mostrarlo\n",
        "# SVG(model_to_dot( model_a1,  show_shapes=True, show_layer_names=True).create(prog='dot', format='svg'))\n",
        "\n",
        "#Compilar modelo\n",
        "model_a1.compile(loss=loss_function, optimizer = optimizer, metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history_mda1 = train_model(model_a1)\n",
        "plot_loss(history_mda1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Arquitectura 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "K.clear_session()\n",
        "tf.random.set_seed(51)\n",
        "np.random.seed(51)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtener el número único de películas y usuarios en el DataFrame\n",
        "n_movies = len(df['movieId'].unique())\n",
        "n_users = len(df['userId'].unique())\n",
        "\n",
        "# Definir la capa de entrada para el usuario con un solo valor entero (userId)\n",
        "user_input = Input(shape=(1,), name='user_input', dtype='int64')\n",
        "\n",
        "# Crear la capa de embedding para usuarios\n",
        "user_embedding = Embedding(n_users, n_latent_factors, name='user_embedding')(user_input)\n",
        "user_vec = Flatten(name='FlattenUsers')(user_embedding)  # Aplanar la salida de la capa de embedding\n",
        "user_vec = Dropout(0.40)(user_vec)  # Aplicar Dropout para regularización\n",
        "\n",
        "# Definir la capa de entrada para la película con un solo valor entero (movieId)\n",
        "movie_input = Input(shape=(1,), name='movie_input', dtype='int64')\n",
        "\n",
        "# Crear la capa de embedding para películas\n",
        "movie_embedding = Embedding(n_movies, n_latent_factors, name='movie_embedding')(movie_input)\n",
        "movie_vec = Flatten(name='FlattenMovies')(movie_embedding)  # Aplanar la salida de la capa de embedding\n",
        "movie_vec = Dropout(0.40)(movie_vec)  # Aplicar Dropout para regularización\n",
        "\n",
        "# Calcular la similitud entre los vectores de usuario y película mediante el producto punto\n",
        "similarity = dot([user_vec, movie_vec], name='Similarity-Dot-Product', axes=1)\n",
        "\n",
        "# Definir una capa de red neuronal para procesar la similitud calculada\n",
        "nn_inp = Dense(96, activation='relu')(similarity)\n",
        "nn_inp = Dropout(0.4)(nn_inp)  # Aplicar Dropout para regularización\n",
        "# nn_inp = BatchNormalization()(nn_inp)  # Normalización por lotes (comentada, opcional)\n",
        "nn_inp = Dense(1, activation='relu')(nn_inp)\n",
        "\n",
        "# Crear el modelo utilizando Model API de Keras\n",
        "model_a2 = Model([user_input, movie_input], nn_inp)\n",
        "model_a2.summary()  # Mostrar resumen del modelo en términos de parámetros y capas\n",
        "\n",
        "# Compilar el modelo con la función de pérdida y el optimizador especificados\n",
        "model_a2.compile(loss=loss_function, optimizer=optimizer, metrics = ['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history_mda2 = train_model(model_a2)\n",
        "plot_loss(history_mda2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Arquitectura 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "K.clear_session()\n",
        "tf.random.set_seed(51)\n",
        "np.random.seed(51)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtener el número único de películas y usuarios en el DataFrame\n",
        "n_movies = len(df['movieId'].unique())\n",
        "n_users = len(df['userId'].unique())\n",
        "\n",
        "# Definir la capa de entrada para el usuario con un solo valor entero (userId)\n",
        "user_input = Input(shape=(1,), name='User_Input')\n",
        "\n",
        "# Crear la capa de embedding para usuarios\n",
        "user_embeddings = Embedding(input_dim=n_users+1, output_dim=n_latent_factors, input_length=1, name='User_Embedding')(user_input)\n",
        "user_vector = Flatten(name='User_Vector')(user_embeddings)  # Aplanar la salida de la capa de embedding\n",
        "\n",
        "# Definir la capa de entrada para la película con un solo valor entero (movieId)\n",
        "movie_input = Input(shape=(1,), name='Movie_input')\n",
        "\n",
        "# Crear la capa de embedding para películas\n",
        "movie_embeddings = Embedding(input_dim=n_movies+1, output_dim=n_latent_factors, input_length=1, name='Movie_Embedding')(movie_input)\n",
        "movie_vector = Flatten(name='Movie_Vector')(movie_embeddings)  # Aplanar la salida de la capa de embedding\n",
        "\n",
        "# Concatenar los vectores de usuario y película\n",
        "merged_vectors = concatenate([user_vector, movie_vector], name='Concatenation')\n",
        "\n",
        "# Capa densa con 100 unidades y función de activación ReLU\n",
        "dense_layer_1 = Dense(100, activation='relu')(merged_vectors)\n",
        "\n",
        "# Aplicar Dropout para regularización\n",
        "dense_layer_3 = Dropout(0.5)(dense_layer_1)\n",
        "\n",
        "# Capa densa de salida con 1 unidad\n",
        "dense_layer_2 = Dense(1)(dense_layer_3)\n",
        "\n",
        "# Crear el modelo utilizando Model API de Keras\n",
        "model_a3 = Model([user_input, movie_input], dense_layer_2)\n",
        "\n",
        "# Compilar el modelo con la función de pérdida, el optimizador y métricas especificados\n",
        "model_a3.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
        "model_a3.summary()  # Mostrar resumen del modelo en términos de parámetros y capas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history_mda3 = train_model(model_a3)\n",
        "plot_loss(history_mda3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Arquitectura 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "K.clear_session()\n",
        "tf.random.set_seed(51)\n",
        "np.random.seed(51)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definición de la entrada del usuario (user_input)\n",
        "user_input = Input(shape=[1], name='user')  # Capa de entrada para la información del usuario.\n",
        "# print(f\"User Input Shape: {user_input.shape}\")\n",
        "\n",
        "# Creación de la capa de embedding para usuarios (user_embedding)\n",
        "user_embedding = Embedding(input_dim=n_users + 1, output_dim=n_latent_factors, name='user_embedding')(user_input)\n",
        "# La capa de embedding asigna a cada usuario un vector en el espacio de factores latentes.\n",
        "# print(f\"User Embedding Shape: {user_embedding.shape}\")\n",
        "\n",
        "# Aplanamiento de la capa de embedding para usuarios (user_vec)\n",
        "user_vec = Flatten(name='flatten_users')(user_embedding)\n",
        "# Se aplana el embedding para obtener un vector unidimensional que representa al usuario en el espacio de factores latentes.\n",
        "# print(f\"Flattened User Vector Shape: {user_vec.shape}\")\n",
        "\n",
        "# Definición de la entrada de la película (movie_input)\n",
        "movie_input = Input(shape=[1], name='movie')  # Capa de entrada para la información de la película.\n",
        "# print(f\"Movie Input Shape: {movie_input.shape}\")\n",
        "\n",
        "# Creación de la capa de embedding para películas (movie_embedding)\n",
        "movie_embedding = Embedding(input_dim=n_movies + 1, output_dim=n_latent_factors, name='movie_embedding')(movie_input)\n",
        "# La capa de embedding asigna a cada película un vector en el espacio de factores latentes.\n",
        "# print(f\"Movie Embedding Shape: {movie_embedding.shape}\")\n",
        "\n",
        "# Aplanamiento de la capa de embedding para películas (movie_vec)\n",
        "movie_vec = Flatten(name='flatten_movies')(movie_embedding)\n",
        "# Se aplana el embedding para obtener un vector unidimensional que representa la película en el espacio de factores latentes.\n",
        "# print(f\"Flattened Movie Vector Shape: {movie_vec.shape}\")\n",
        "\n",
        "# Cálculo del producto punto entre los vectores de película y usuario (product)\n",
        "product = dot([movie_vec, user_vec], axes=1)\n",
        "# El modelo calcula el producto punto entre los vectores de película y usuario para predecir las calificaciones.\n",
        "# print(f\"Product Shape: {product.shape}\")\n",
        "\n",
        "# Definición del modelo (model)\n",
        "model_a4 = Model(inputs=[user_input, movie_input], outputs=product)\n",
        "\n",
        "# Compilación del modelo con la función de pérdida y optimizador\n",
        "model_a4.compile(loss=loss_function, optimizer = optimizer, metrics = ['accuracy'])\n",
        "\n",
        "model_a4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history_mda4 = train_model(model_a4)\n",
        "plot_loss(history_mda4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Arquitectura 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "K.clear_session()\n",
        "tf.random.set_seed(51)\n",
        "np.random.seed(51)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir la entrada del usuario y su embedding\n",
        "user_input = Input(shape=[1], name='user')\n",
        "user_embedding = Embedding(input_dim=n_users + 1, output_dim=n_latent_factors, name='user_embedding')(user_input)\n",
        "user_vec = Flatten(name='flatten_users')(user_embedding)\n",
        "\n",
        "# Definir la entrada de la película y su embedding\n",
        "movie_input = Input(shape=[1], name='movie')\n",
        "movie_embedding = Embedding(input_dim=n_movies + 1, output_dim=n_latent_factors, name='movie_embedding')(movie_input)\n",
        "movie_vec = Flatten(name='flatten_movies')(movie_embedding)\n",
        "\n",
        "# Concatenar los embeddings de usuario y película\n",
        "concatenated = concatenate([user_vec, movie_vec], name='Concatenation')\n",
        "\n",
        "# Añadir capas Dense con activación ReLU\n",
        "dense_layer1 = Dense(128, activation='relu')(concatenated)\n",
        "dense_layer2 = Dense(64, activation='relu')(dense_layer1)\n",
        "dense_layer3 = Dense(32, activation='relu')(dense_layer2)\n",
        "\n",
        "# Capa de salida con activación lineal\n",
        "output = Dense(1, activation='linear')(dense_layer3)\n",
        "\n",
        "# Crear el modelo con métrica R cuadrado\n",
        "model_a5 = Model(inputs=[user_input, movie_input], outputs=output)\n",
        "\n",
        "# Compilación del modelo con la función de pérdida y optimizador\n",
        "model_a5.compile(loss=loss_function, optimizer = optimizer, metrics = ['accuracy'])\n",
        "\n",
        "model_a5.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history_mda5 = train_model(model_a5)\n",
        "plot_loss(history_mda5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Arquitectura 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "K.clear_session()\n",
        "tf.random.set_seed(51)\n",
        "np.random.seed(51)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_input = Input(shape=(1,), name=\"user_id\", dtype=tf.int32)\n",
        "item_input = Input(shape=(1,), name=\"item_id\", dtype=tf.int32)\n",
        " \n",
        "user_embedding = Embedding(n_users,\n",
        "                                  n_latent_factors,\n",
        "                                  name=\"user_emb\")(user_input)\n",
        "user_bias = Embedding(n_users, 1, name=\"user_bias\")(user_input)\n",
        " \n",
        "item_embedding = Embedding(n_movies,\n",
        "                                  n_latent_factors,\n",
        "                                  name=\"item_emb\")(item_input)\n",
        "item_bias = Embedding(n_movies, 1, name=\"item_bias\")(item_input)\n",
        " \n",
        "user_vector = Flatten()(user_embedding)\n",
        "item_vector = Flatten()(item_embedding)\n",
        " \n",
        "dot_user_item = Dot(name=\"dot\", axes=1)([user_vector, item_vector])\n",
        "output = Add(name=\"add\")([dot_user_item, user_bias, item_bias])\n",
        "output = Flatten(name=\"flat\")(output)\n",
        " \n",
        "model_a6 = Model([user_input, item_input], output, name=\"model_x\")\n",
        " \n",
        "model_a6.compile(loss=loss_function, optimizer = optimizer, metrics = ['accuracy'])\n",
        " \n",
        "model_a6.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history_mda6 = train_model(model_a6)\n",
        "plot_loss(history_mda6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Arquitectura 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "K.clear_session()\n",
        "tf.random.set_seed(51)\n",
        "np.random.seed(51)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hidden_units = [128, 64]\n",
        " \n",
        "user_input = Input(shape=(1,), name=\"user_id\", dtype=tf.int32)\n",
        "item_input = Input(shape=(1,), name=\"item_id\", dtype=tf.int32)\n",
        "user_embedding = Embedding(n_users,\n",
        "                                  n_latent_factors,\n",
        "                                  name=\"user_emb\")(user_input)\n",
        "item_embedding = Embedding(n_movies,\n",
        "                                  n_latent_factors,\n",
        "                                  name=\"item_emb\")(item_input)\n",
        "\n",
        "concatenated = Concatenate(name=\"concat\")([user_embedding, item_embedding])\n",
        "out = Flatten(name=\"flat\")(concatenated)\n",
        " \n",
        "for n_hidden in hidden_units:\n",
        "    out = Dense(n_hidden,\n",
        "                       activation=\"relu\")(out)\n",
        "    out = Dropout(0.4)(out)\n",
        "    out = BatchNormalization()(out)\n",
        "\n",
        "out = Dense(1, activation=\"sigmoid\", name=\"prediction\")(out)\n",
        " \n",
        "model_a67 = Model(inputs = [user_input, item_input],\n",
        "                      outputs = out, name=\"model_y\")\n",
        " \n",
        "model_a67.compile(loss=loss_function, optimizer = optimizer, metrics = ['accuracy'])\n",
        " \n",
        "model_a67.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history_mda7 = train_model(model_a6)\n",
        "plot_loss(history_mda7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Evaluation\n",
        "\n",
        "Intentamos medir el rendimiento del modelo proporcionando productos candidatos al modelo y evaluando los resultados. Los productos candidatos se combinan con 49 productos seleccionados entre los productos no comprados y un producto objetivo representado en la variable output_sequence. Si el producto objetivo aparece en los k primeros resultados del modelo, lo consideramos un acierto.\n",
        "\n",
        "Por otro lado; Hidasi y Karatzoglou (2018) definen \"recall@k\" como una métrica de evaluación como \"la proporción de casos que tienen el elemento deseado entre los primeros k elementos en todos los casos de prueba.\" Además, otra métrica de evaluación es \"MRR@k\", que es la media de los rangos recíprocos de los ítems objetivo. El rango recíproco se fija en cero si el rango es superior a k."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
